#include "gradientdescentoptimiser.h"

#ifdef ADAGRAD

__global__ void crossbowKernelGradientDescentOptimiserPow 
	(const int count, const float* a, const float alpha, float* y) {
	CUDA_KERNEL_LOOP (index, count) {
		y[index] = pow(a[index], alpha);
	}
}

__global__ void crossbowKernelGradientDescentOptimiserAddScalar 
	(const int count, const float alpha, float* y) {
	CUDA_KERNEL_LOOP (index, count) {
		y[index] += alpha;
	}
}

__global__ void crossbowKernelGradientDescentOptimiserDiv
	(const int count, float* a, float *b, float* y) {
	CUDA_KERNEL_LOOP(index, count) {
		y[index] = a[index] / b[index];
	}
}

#endif

#ifndef UPDATE_MODEL_INCREMENTALLY

static void crossbowKernelGradientDescentOptimiserWorkerModelUpdate (crossbowStreamP s) {
	
	float minusone = -1;
	float one = 1;

	float rate;

	int elements = s->model->elements;

	/* Get replica model data buffer */
	crossbowDataBufferP model = s->model->data;

	/* Get replica model gradient data buffer */
	crossbowDataBufferP gradient = s->model->gradient;

	/* Get base model gradient data buffer */
	crossbowDataBufferP theGradient = s->theModel->gradient;

	/* Apply weight decay to gradient, if configured */
	if (s->model->conf->weightDecay > 0)
		checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(s->model->conf->weightDecay), (float *) (model->dev), 1, (float *) (gradient->dev), 1));
	
	
	// checkCudaErrors(cudaDeviceSynchronize());
	//
	// float checksum = crossbowDataBufferComputeCheckSum(gradient, 0, s->model->bytes);
	// info("Gradient checksum of task %d is %.5f\n", s->task, checksum);
	
	/* Record event that replica model gradient is ready to be used by the parameter server */
	checkCudaErrors(cudaEventRecord (s->model->client, s->stream[s->op->branch]));

	/* Accumulate replica model gradient to base model gradient, applying learning rate */
	checkCudaErrors(cudaStreamWaitEvent(s->modelSynchronisationStream, s->model->client, 0));

	if (s->model->conf->momentumMethod == NESTEROV) {
		checkCublasStatus(cublasSaxpy (s->modelSynchronisationHandle, elements, &(one), (float *) (gradient->dev), 1, (float *) (theGradient->dev), 1));
	}
	else {
		rate = minusone * crossbowSolverConfGetLearningRate (s->model->conf, s->task);
		checkCublasStatus(cublasSaxpy (s->modelSynchronisationHandle, elements, &(rate), (float *) (gradient->dev), 1, (float *) (theGradient->dev), 1));
	}

	/* Record event that replica model gradient is not longer required by the parameter server */
	checkCudaErrors(cudaEventRecord(s->model->server, s->modelSynchronisationStream));

	return;
}

static void crossbowKernelGradientDescentOptimiserDownpourModelUpdate (crossbowStreamP s) {

	float minusone = -1;
	// float one = 1;

	float rate;

	int elements = s->model->elements;

	/* Get replica model data buffer */
	crossbowDataBufferP model = s->model->data;

	/* Get replica model gradient data buffer */
	crossbowDataBufferP gradient = s->model->gradient;

	/* Get base model gradient data buffer */
	// crossbowDataBufferP theGradient = s->theModel->gradient;

	/* Apply weight decay to gradient, if configured */
	if (s->model->conf->weightDecay > 0)
		checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(s->model->conf->weightDecay), (float *) (model->dev), 1, (float *) (gradient->dev), 1));

	/*
	float checksum = crossbowDataBufferComputeCheckSum(gradient, 0, s->model->bytes);
	info("Gradient checksum of task %d is %.5f\n", s->task, checksum);
	 */

	rate = minusone * crossbowSolverConfGetLearningRate (s->model->conf, s->task);

	/* Scale gradient based on learning rate */
	checkCublasStatus(cublasSscal(s->cublasHandle[s->op->branch], elements, &(rate), (float *) (gradient->dev), 1));

	/* Record event that replica model gradient is ready to be used by the parameter server */
	checkCudaErrors(cudaEventRecord (s->model->client, s->stream[s->op->branch]));

	return;
}

/*
static void crossbowKernelGradientDescentOptimiserMultiGPUWorkerModelUpdate (crossbowStreamP s) {
	return;
}
*/

static void crossbowKernelGradientDescentOptimiserSynchronousEamsgdModelUpdate (crossbowStreamP s) {

	crossbowDataBufferP model, gradient, last;
	float rate;

	int elements;

	/* Constants */
	float one = 1;
	float minusone = -1;

	/* Get model replica data buffer */
	model = s->model->data;

	/* Get current and gradient data buffer */
	gradient = s->model->gradient;
	last = s->model->last;

	elements = s->model->elements;

	/* Apply weight decay */
	if (s->model->conf->weightDecay > 0)
		checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(s->model->conf->weightDecay), (float *) (model->dev), 1, (float *) (gradient->dev), 1));
	
	/*
	checkCudaErrors(cudaDeviceSynchronize());

	float checksum = crossbowDataBufferComputeCheckSum(gradient, 0, s->model->bytes);
	info("Gradient checksum of task %d is %.5f\n", s->task, checksum);
	*/

	rate = minusone * crossbowSolverConfGetLearningRate(s->model->conf, s->task);

	if (s->model->conf->momentum > 0) {

		if (s->model->conf->momentumMethod == NESTEROV) {
			/* Scale last based on momentum */
			checkCublasStatus(cublasSscal(s->cublasHandle[s->op->branch], elements, &(s->model->conf->momentum), (float *) (last->dev), 1));

			/* Add gradient to last */
			checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(one), (float *) (gradient->dev), 1, (float *) (last->dev), 1));

			/* Add last to gradient, scaled by momentum */
			checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(s->model->conf->momentum), (float *) (last->dev), 1, (float *) (gradient->dev), 1));

			/* Apply gradient to local model */
			checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(rate), (float *) (gradient->dev), 1, (float *) (model->dev), 1));
		}
		else {
			
			/* Scale gradient based on learning rate */
			checkCublasStatus(cublasSscal(s->cublasHandle[s->op->branch], elements, &(rate), (float *) (gradient->dev), 1));

			/* Apply momentum to gradient */
			checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(s->model->conf->momentum), (float *) (last->dev), 1, (float *) (gradient->dev), 1));
		
			/* Copy current gradient buffer into last */
			checkCudaErrors(cudaMemcpyAsync(last->dev, gradient->dev, s->model->bytes, cudaMemcpyDeviceToDevice, s->stream[s->op->branch]));

			/* Apply last to local model */
			checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(one), (float *) (gradient->dev), 1, (float *) (model->dev), 1));
		}
	}
	else {
#ifdef ADAGRAD			
		/* AdaGrad begin */

		crossbowKernelGradientDescentOptimiserPow<<<GET_BLOCKS(elements), CUDA_NUM_THREADS, 0, s->stream[s->op->branch]>>>
			(elements, (float *) (gradient->dev), 2.0F, (float *) (s->model->tmp1->dev));

		checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(one), (float *) (s->model->tmp1->dev), 1, (float *) (s->model->hist->dev), 1));
			
		crossbowKernelGradientDescentOptimiserPow<<<GET_BLOCKS(elements), CUDA_NUM_THREADS, 0, s->stream[s->op->branch]>>>
			(elements, (float *) (s->model->hist->dev), 0.5F, (float *) (s->model->tmp1->dev));
			
		crossbowKernelGradientDescentOptimiserAddScalar<<<GET_BLOCKS(elements), CUDA_NUM_THREADS, 0, s->stream[s->op->branch]>>>
			(elements, 1e-8F, (float *) (s->model->tmp1->dev));

		crossbowKernelGradientDescentOptimiserDiv<<<GET_BLOCKS(elements), CUDA_NUM_THREADS, 0, s->stream[s->op->branch]>>>
			(elements, (float *) (gradient->dev), (float *) (s->model->tmp1->dev), (float *) (gradient->dev));

		/* AdaGrad end */
#endif
		
		/* Apply gradient to local model */
		checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(rate), (float *) (gradient->dev), 1, (float *) (model->dev), 1));
	}
}

/*
static void crossbowKernelGradientDescentOptimiserMultiGPUSynchronousEamsgdModelUpdate (crossbowStreamP s) {
	return;
}
*/

static void crossbowKernelGradientDescentOptimiserDefaultModelUpdate (crossbowStreamP s) {

	crossbowDataBufferP model, gradient, last, theModel;
	float rate;

	int elements;

	/* Constants */
	float one = 1;
	float minusone = -1;

	/* Get model replica data buffer */
	model = s->model->data;

	/* Get current and gradient data buffer */
	gradient = s->model->gradient;
	last = s->model->last;

	/* Get base model data buffer */
	theModel = s->theModel->data;

	elements = s->model->elements;

	/* TODO Scale gradient by 1 over batch size? */

	/* Apply weight decay */
	if (s->model->conf->weightDecay > 0)
		checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(s->model->conf->weightDecay), (float *) (model->dev), 1, (float *) (gradient->dev), 1));

	rate = minusone * crossbowSolverConfGetLearningRate(s->model->conf, s->task);

	if (s->model->conf->momentum > 0) {

		if (s->model->conf->momentumMethod == NESTEROV) {
			/* Scale last based on momentum */
			checkCublasStatus(cublasSscal(s->cublasHandle[s->op->branch], elements, &(s->model->conf->momentum), (float *) (last->dev), 1));

			/* Add gradient to last */
			checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(one), (float *) (gradient->dev), 1, (float *) (last->dev), 1));

			/* Add last to gradient, scaled by momentum */
			checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(s->model->conf->momentum), (float *) (last->dev), 1, (float *) (gradient->dev), 1));

			/* Record event that gradient is ready to be used by parameter server */
			checkCudaErrors(cudaEventRecord (s->model->client, s->stream[s->op->branch]));

			/* Apply gradient to local model */
			checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(rate), (float *) (gradient->dev), 1, (float *) (model->dev), 1));

			/* Apply gradient to parameter server model (base model) */
			checkCudaErrors(cudaStreamWaitEvent(s->modelSynchronisationStream, s->model->client, 0));

			checkCublasStatus(cublasSaxpy (s->modelSynchronisationHandle, elements, &(rate), (float *) (gradient->dev), 1, (float *) (theModel->dev), 1));

			checkCudaErrors(cudaEventRecord(s->model->server, s->modelSynchronisationStream));
		}
		else {
			/* Scale gradient based on learning rate */
			checkCublasStatus(cublasSscal(s->cublasHandle[s->op->branch], elements, &(rate), (float *) (gradient->dev), 1));

			/* Apply momentum to gradient */
			checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(s->model->conf->momentum), (float *) (last->dev), 1, (float *) (gradient->dev), 1));
		
			/* Record event that gradient is ready to be used by parameter server */
			checkCudaErrors(cudaEventRecord (s->model->client, s->stream[s->op->branch]));

			/* Copy current gradient into last */
			checkCudaErrors(cudaMemcpyAsync(last->dev, gradient->dev, s->model->bytes, cudaMemcpyDeviceToDevice, s->stream[s->op->branch]));

			/* Apply gradient to local model */
			checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(one), (float *) (gradient->dev), 1, (float *) (model->dev), 1));

			/* Apply gradient to parameter server model (base model) */
			checkCudaErrors(cudaStreamWaitEvent(s->modelSynchronisationStream, s->model->client, 0));

			checkCublasStatus(cublasSaxpy (s->modelSynchronisationHandle, elements, &(one), (float *) (gradient->dev), 1, (float *) (theModel->dev), 1));

			checkCudaErrors(cudaEventRecord(s->model->server, s->modelSynchronisationStream));
		}
	}
	else {
#ifdef ADAGRAD			
		/* AdaGrad begin */
			
		crossbowKernelGradientDescentOptimiserPow<<<GET_BLOCKS(elements), CUDA_NUM_THREADS, 0, s->stream[s->op->branch]>>>
			(elements, (float *) (gradient->dev), 2.0F, (float *) (s->model->tmp1->dev));

		checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(one), (float *) (s->model->tmp1->dev), 1, (float *) (s->model->hist->dev), 1));
			
		crossbowKernelGradientDescentOptimiserPow<<<GET_BLOCKS(elements), CUDA_NUM_THREADS, 0, s->stream[s->op->branch]>>>
			(elements, (float *) (s->model->hist->dev), 0.5F, (float *) (s->model->tmp1->dev));
			
		crossbowKernelGradientDescentOptimiserAddScalar<<<GET_BLOCKS(elements), CUDA_NUM_THREADS, 0, s->stream[s->op->branch]>>>
			(elements, 1e-8F, (float *) (s->model->tmp1->dev));

		crossbowKernelGradientDescentOptimiserDiv<<<GET_BLOCKS(elements), CUDA_NUM_THREADS, 0, s->stream[s->op->branch]>>>
			(elements, (float *) (gradient->dev), (float *) (s->model->tmp1->dev), (float *) (gradient->dev));

		/* AdaGrad end */
#endif
		
		/* Record event that gradient is ready to be used by parameter server */
		checkCudaErrors(cudaEventRecord (s->model->client, s->stream[s->op->branch]));

		/* Apply gradient to local model */
		checkCublasStatus(cublasSaxpy (s->cublasHandle[s->op->branch], elements, &(rate), (float *) (gradient->dev), 1, (float *) (model->dev), 1));

		/* Apply gradient to parameter server model (base model) */
		checkCudaErrors(cudaStreamWaitEvent(s->modelSynchronisationStream, s->model->client, 0));

		checkCublasStatus(cublasSaxpy (s->modelSynchronisationHandle, elements, &(rate), (float *) (gradient->dev), 1, (float *) (theModel->dev), 1));

		checkCudaErrors(cudaEventRecord(s->model->server, s->modelSynchronisationStream));
	}

	return;
}

#endif /* End of function definitions */

void crossbowKernelGradientDescentOptimiser (void *args) {

#ifdef UPDATE_MODEL_INCREMENTALLY
	/* Do nothing */
 	(void) args;
#else

	crossbowStreamP s = (crossbowStreamP) args;

	switch (s->model->type) {

	case DEFAULT:
		dbg("Update replica using default model\n");
		switch (s->mode) {
		case SINGLE_GPU:
		case  MULTI_GPU:
			crossbowKernelGradientDescentOptimiserDefaultModelUpdate (s);
			break;
		default:
			err("Invalid model synchronisation mode\n");
		}
		break;

	case WORKER:
		dbg("Update replica using worker model\n");
		switch (s->mode) {
		case SINGLE_GPU:
		case  MULTI_GPU:
			crossbowKernelGradientDescentOptimiserWorkerModelUpdate  (s);
			break;
		default:
			err("Invalid model synchronisation mode\n");
		}
		break;

	/* case EAMSGD: break; */

	case SYNCHRONOUSEAMSGD:
		dbg("Update replica using synchronous EAMSGD model\n");
		switch (s->mode) {
		case SINGLE_GPU:
		case MULTI_GPU:
			crossbowKernelGradientDescentOptimiserSynchronousEamsgdModelUpdate  (s);
			break;
		default:
			err("Invalid model synchronisation mode\n");
		}
		break;

	case DOWNPOUR:
		dbg("Update replica using (synchronous) DOWNPOUR model\n");
		switch (s->mode) {
		case SINGLE_GPU:
		case MULTI_GPU:
			crossbowKernelGradientDescentOptimiserDownpourModelUpdate  (s);
			break;
		default:
			err("Invalid model synchronisation mode\n");
		}
		break;

	default:
		err("Invalid model update type\n");
	}

#endif /* UPDATE_MODEL_INCREMENTALLY */

	return;
}
